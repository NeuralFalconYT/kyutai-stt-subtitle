{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Kyutai STT GitHub](https://github.com/kyutai-labs/delayed-streams-modeling)"
      ],
      "metadata": {
        "id": "J6K0iK2aNmcX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "NuGVXlhkHSF3"
      },
      "outputs": [],
      "source": [
        "#@title Install Kyutai STT\n",
        "# !pip install moshi\n",
        "!pip install 'sphn<0.2'\n",
        "!pip install --no-deps \"moshi==0.2.7\"\n",
        "!pip install gradio>=5.35.0\n",
        "!pip install julius\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!wget https://github.com/kyutai-labs/moshi/raw/refs/heads/main/data/sample_fr_hibiki_crepes.mp3\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Works better without music and background noise\n",
        "import itertools\n",
        "import dataclasses\n",
        "import julius\n",
        "import sphn\n",
        "import math\n",
        "import json\n",
        "import torch\n",
        "import gc\n",
        "import tqdm\n",
        "import moshi.models\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class TimestampedText:\n",
        "    text: str\n",
        "    timestamp: tuple[float, float]\n",
        "\n",
        "\n",
        "def tokens_to_timestamped_text(text_tokens, tokenizer, frame_rate, end_of_padding_id, padding_token_id, offset_seconds):\n",
        "    text_tokens = text_tokens.cpu().view(-1)\n",
        "    sequence_timestamps = []\n",
        "\n",
        "    def _tstmp(start, end):\n",
        "        return (\n",
        "            max(0, start / frame_rate - offset_seconds),\n",
        "            max(0, end / frame_rate - offset_seconds),\n",
        "        )\n",
        "\n",
        "    def _decode(t):\n",
        "        t = t[t > padding_token_id]\n",
        "        return tokenizer.decode(t.numpy().tolist())\n",
        "\n",
        "    def _decode_segment(start, end):\n",
        "        start = int(start)\n",
        "        end = int(end)\n",
        "        text = _decode(text_tokens[start:end])\n",
        "        words = text.split()\n",
        "        if not words:\n",
        "            return\n",
        "        if len(words) == 1:\n",
        "            sequence_timestamps.append(TimestampedText(text=text, timestamp=_tstmp(start, end)))\n",
        "        else:\n",
        "            for word in words[:-1]:\n",
        "                n_tokens = len(tokenizer.encode(word))\n",
        "                sequence_timestamps.append(TimestampedText(text=word, timestamp=_tstmp(start, start + n_tokens)))\n",
        "                start += n_tokens\n",
        "            sequence_timestamps.append(TimestampedText(text=words[-1], timestamp=_tstmp(start, end)))\n",
        "\n",
        "    (segment_boundaries,) = torch.where(text_tokens == end_of_padding_id)\n",
        "    if not segment_boundaries.numel():\n",
        "        return []\n",
        "\n",
        "    for i in range(len(segment_boundaries) - 1):\n",
        "        _decode_segment(segment_boundaries[i] + 1, segment_boundaries[i + 1])\n",
        "\n",
        "    last_start = int(segment_boundaries[-1] + 1)\n",
        "    (last_end,) = torch.where(torch.isin(text_tokens[last_start:], torch.tensor([tokenizer.eos_id()])))\n",
        "    last_end = last_start + (int(last_end[0]) if last_end.numel() else frame_rate)\n",
        "    _decode_segment(last_start, last_end)\n",
        "\n",
        "    return sequence_timestamps\n",
        "\n",
        "\n",
        "def load_model(hf_repo=\"kyutai/stt-2.6b-en\", device=\"cuda\"):\n",
        "    info = moshi.models.loaders.CheckpointInfo.from_hf_repo(hf_repo)\n",
        "    mimi = info.get_mimi(device=device)\n",
        "    moshi_model = info.get_moshi(device=device, dtype=torch.bfloat16)\n",
        "    tokenizer = info.get_text_tokenizer()\n",
        "    lm_gen = moshi.models.LMGen(moshi_model, temp=0, temp_text=0.0)\n",
        "\n",
        "    return {\n",
        "        \"info\": info,\n",
        "        \"mimi\": mimi,\n",
        "        \"lm\": moshi_model,\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"lm_gen\": lm_gen,\n",
        "        \"device\": device\n",
        "    }\n",
        "\n",
        "\n",
        "def run_transcription(model, audio_path, save_json_path=\"word_timestamps.json\"):\n",
        "    info = model[\"info\"]\n",
        "    mimi = model[\"mimi\"]\n",
        "    lm_gen = model[\"lm_gen\"]\n",
        "    tokenizer = model[\"tokenizer\"]\n",
        "    device = model[\"device\"]\n",
        "\n",
        "    silence_prefix = info.stt_config.get(\"audio_silence_prefix_seconds\", 1.0)\n",
        "    audio_delay = info.stt_config.get(\"audio_delay_seconds\", 5.0)\n",
        "    pad_id = info.raw_config.get(\"text_padding_token_id\", 3)\n",
        "\n",
        "    audio, sr = sphn.read(audio_path)\n",
        "    audio = torch.from_numpy(audio).to(device)\n",
        "    audio = julius.resample_frac(audio, sr, mimi.sample_rate)\n",
        "    if audio.shape[-1] % mimi.frame_size != 0:\n",
        "        pad = mimi.frame_size - audio.shape[-1] % mimi.frame_size\n",
        "        audio = torch.nn.functional.pad(audio, (0, pad))\n",
        "\n",
        "    prefix_chunks = math.ceil(silence_prefix * mimi.frame_rate)\n",
        "    suffix_chunks = math.ceil(audio_delay * mimi.frame_rate)\n",
        "    silence = torch.zeros((1, 1, mimi.frame_size), dtype=torch.float32, device=device)\n",
        "    chunks = itertools.chain(\n",
        "        itertools.repeat(silence, prefix_chunks),\n",
        "        torch.split(audio[:, None], mimi.frame_size, dim=-1),\n",
        "        itertools.repeat(silence, suffix_chunks)\n",
        "    )\n",
        "\n",
        "    all_tokens = []\n",
        "    with mimi.streaming(1), lm_gen.streaming(1):\n",
        "        for chunk in tqdm.tqdm(chunks):\n",
        "            audio_tokens = mimi.encode(chunk)\n",
        "            text_tokens = lm_gen.step(audio_tokens)\n",
        "            if text_tokens is not None:\n",
        "                all_tokens.append(text_tokens)\n",
        "\n",
        "    utterance_tokens = torch.concat(all_tokens, dim=-1)\n",
        "    offset = prefix_chunks / mimi.frame_rate + audio_delay\n",
        "    timestamped = tokens_to_timestamped_text(\n",
        "        utterance_tokens,\n",
        "        tokenizer,\n",
        "        mimi.frame_rate,\n",
        "        end_of_padding_id=0,\n",
        "        padding_token_id=pad_id,\n",
        "        offset_seconds=offset,\n",
        "    )\n",
        "\n",
        "    transcription_words = []\n",
        "    word_timestamps = []\n",
        "\n",
        "    for t in timestamped:\n",
        "        transcription_words.append(t.text)\n",
        "        word_timestamps.append({\n",
        "            \"word\": t.text,\n",
        "            \"start\": t.timestamp[0],\n",
        "            \"end\": t.timestamp[1]\n",
        "        })\n",
        "\n",
        "    transcription = \" \".join(transcription_words)\n",
        "\n",
        "    if save_json_path:\n",
        "        with open(save_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump({\n",
        "                \"transcription\": transcription,\n",
        "                \"word_timestamps\": word_timestamps\n",
        "            }, f, indent=2)\n",
        "        print(f\"Saved: {save_json_path}\")\n",
        "\n",
        "    return transcription, word_timestamps\n",
        "\n",
        "\n",
        "def unload_model(model):\n",
        "    model[\"mimi\"].to(\"cpu\")\n",
        "    model[\"lm\"].to(\"cpu\")\n",
        "    torch.cuda.empty_cache()\n",
        "    del model\n",
        "    gc.collect()\n",
        "    print(\"Model unloaded and memory freed.\")\n",
        "\n",
        "import subprocess\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "def ensure_mono(audio_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Ensure an audio file is mono. If stereo, converts to mono using FFmpeg.\n",
        "    Returns the path to the mono audio file (original or new).\n",
        "    Raises RuntimeError if conversion fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with sf.SoundFile(audio_path) as f:\n",
        "            channels = f.channels\n",
        "\n",
        "        if channels == 1:\n",
        "            print(f\"✅ Audio is already mono: {audio_path}\")\n",
        "            return audio_path\n",
        "\n",
        "        print(f\"⚠️ Audio is stereo (channels={channels}), converting to mono MP3...\")\n",
        "\n",
        "        base, _ = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "        mono_path = f\"./subtitle/{base}_mono.mp3\"\n",
        "\n",
        "        # Remove stale output if exists\n",
        "        if os.path.exists(mono_path):\n",
        "            os.remove(mono_path)\n",
        "\n",
        "        # Run FFmpeg conversion\n",
        "        command = [\n",
        "            \"ffmpeg\", \"-i\", audio_path,\n",
        "            \"-ac\", \"1\",\n",
        "            \"-y\", mono_path\n",
        "        ]\n",
        "        subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "        # Validate conversion success\n",
        "        if not os.path.isfile(mono_path) or os.path.getsize(mono_path) == 0:\n",
        "            raise RuntimeError(f\"FFmpeg failed: '{mono_path}' not created or is empty.\")\n",
        "\n",
        "        print(f\"✅ Converted to mono MP3: {mono_path}\")\n",
        "        return mono_path\n",
        "\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Mono conversion failed for '{audio_path}': {e}\") from e\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def convert_video_to_mono_mp3(video_path):\n",
        "    # Create output path by replacing extension\n",
        "    base=os.path.splitext(os.path.basename(video_path))[0]\n",
        "    mono_mp3_path = \"./subtitle/\"+base + \"_mono.mp3\"\n",
        "    if os.path.exists(mono_mp3_path):\n",
        "        os.remove(mono_mp3_path)\n",
        "    # FFmpeg command\n",
        "    command = [\n",
        "        \"ffmpeg\", \"-i\", video_path,   # Input video file\n",
        "        \"-vn\",                        # Remove video\n",
        "        \"-ac\", \"1\",                   # Mono audio\n",
        "        \"-ar\", \"44100\",               # Optional: Set sample rate\n",
        "        \"-y\",                         # Overwrite output\n",
        "        mono_mp3_path\n",
        "    ]\n",
        "\n",
        "    # Run command silently\n",
        "    subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    # print(\"✅ Saved to:\", mono_mp3_path)\n",
        "    return mono_mp3_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import string\n",
        "\n",
        "def write_word_srt(word_level_timestamps, output_file=\"word.srt\", skip_punctuation=True):\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        index = 1  # Track subtitle numbering separately\n",
        "\n",
        "        for entry in word_level_timestamps:\n",
        "            word = entry[\"word\"]\n",
        "\n",
        "            # Skip punctuation if enabled\n",
        "            if skip_punctuation and all(char in string.punctuation for char in word):\n",
        "                continue\n",
        "\n",
        "            start_time = entry[\"start\"]\n",
        "            end_time = entry[\"end\"]\n",
        "\n",
        "            # Convert seconds to SRT time format (HH:MM:SS,mmm)\n",
        "            def format_srt_time(seconds):\n",
        "                hours = int(seconds // 3600)\n",
        "                minutes = int((seconds % 3600) // 60)\n",
        "                sec = int(seconds % 60)\n",
        "                millisec = int((seconds % 1) * 1000)\n",
        "                return f\"{hours:02}:{minutes:02}:{sec:02},{millisec:03}\"\n",
        "\n",
        "            start_srt = format_srt_time(start_time)\n",
        "            end_srt = format_srt_time(end_time)\n",
        "\n",
        "            # Write entry to SRT file\n",
        "            f.write(f\"{index}\\n{start_srt} --> {end_srt}\\n{word}\\n\\n\")\n",
        "            index += 1  # Increment subtitle number\n",
        "\n",
        "def split_line_by_char_limit(text, max_chars_per_line=38):\n",
        "    \"\"\"\n",
        "    Formats a text block into lines with a maximum character limit.\n",
        "    Returns a list of strings (the lines).\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        if not current_line:\n",
        "            current_line = word\n",
        "        elif len(current_line + \" \" + word) <= max_chars_per_line:\n",
        "            current_line += \" \" + word\n",
        "        else:\n",
        "            lines.append(current_line)\n",
        "            current_line = word\n",
        "    if current_line:\n",
        "        lines.append(current_line)\n",
        "    return lines\n",
        "\n",
        "\n",
        "def write_sentence_srt(\n",
        "    word_level_timestamps,\n",
        "    output_file=\"subtitles_professional.srt\",\n",
        "    max_lines=2,\n",
        "    max_duration_s=7.0,\n",
        "    max_chars_per_line=38,\n",
        "    hard_pause_threshold=0.5,\n",
        "    merge_pause_threshold=0.4 # NEW: Threshold for merging single-word orphans\n",
        "):\n",
        "    \"\"\"\n",
        "    Creates professional-grade SRT files using a two-phase process:\n",
        "    1. Generates visually-aware subtitles.\n",
        "    2. Performs a post-processing pass to merge single-word orphans.\n",
        "    \"\"\"\n",
        "    if not word_level_timestamps:\n",
        "        return\n",
        "\n",
        "    # --- PHASE 1: Generate good \"draft\" subtitles ---\n",
        "    draft_subtitles = []\n",
        "    i = 0\n",
        "    while i < len(word_level_timestamps):\n",
        "        start_time = word_level_timestamps[i][\"start\"]\n",
        "        current_words = []\n",
        "\n",
        "        j = i\n",
        "        while j < len(word_level_timestamps):\n",
        "            entry = word_level_timestamps[j]\n",
        "            potential_words = current_words + [entry[\"word\"]]\n",
        "            potential_text = \" \".join(potential_words)\n",
        "\n",
        "            # Check hard limits before adding the word\n",
        "            if len(split_line_by_char_limit(potential_text, max_chars_per_line)) > max_lines: break\n",
        "            if (entry[\"end\"] - start_time) > max_duration_s and current_words: break\n",
        "\n",
        "            if j > i:\n",
        "                prev_entry = word_level_timestamps[j-1]\n",
        "                pause = entry[\"start\"] - prev_entry[\"end\"]\n",
        "                if pause >= hard_pause_threshold: break\n",
        "                if prev_entry[\"word\"].endswith(('.','!','?')): break\n",
        "\n",
        "            current_words.append(entry[\"word\"])\n",
        "            j += 1\n",
        "\n",
        "        if not current_words:\n",
        "            current_words.append(word_level_timestamps[i][\"word\"])\n",
        "            j = i + 1\n",
        "\n",
        "        text = \" \".join(current_words)\n",
        "        end_time = word_level_timestamps[j - 1][\"end\"]\n",
        "        draft_subtitles.append({ \"start\": start_time, \"end\": end_time, \"text\": text })\n",
        "        i = j\n",
        "\n",
        "    # --- PHASE 2: Post-processing to merge single-word orphans ---\n",
        "    if not draft_subtitles:\n",
        "        return\n",
        "\n",
        "    final_subtitles = [draft_subtitles[0]]\n",
        "    for k in range(1, len(draft_subtitles)):\n",
        "        prev_sub = final_subtitles[-1]\n",
        "        current_sub = draft_subtitles[k]\n",
        "\n",
        "        # Check if current subtitle is a single-word orphan\n",
        "        is_single_word_orphan = len(current_sub[\"text\"].split()) == 1\n",
        "        pause_from_prev = current_sub[\"start\"] - prev_sub[\"end\"]\n",
        "\n",
        "        if is_single_word_orphan and pause_from_prev < merge_pause_threshold:\n",
        "            # Attempt to merge it backwards\n",
        "            merged_text = prev_sub[\"text\"] + \" \" + current_sub[\"text\"]\n",
        "\n",
        "            # Only merge if it doesn't violate the line limit\n",
        "            if len(split_line_by_char_limit(merged_text, max_chars_per_line)) <= max_lines:\n",
        "                # Success! Update the previous subtitle instead of adding a new one.\n",
        "                prev_sub[\"text\"] = merged_text\n",
        "                prev_sub[\"end\"] = current_sub[\"end\"]\n",
        "                continue # Skip adding the current_sub as it's been merged\n",
        "\n",
        "        # If not merged, just add the current subtitle as is\n",
        "        final_subtitles.append(current_sub)\n",
        "\n",
        "    # --- Write the final, polished SRT file ---\n",
        "    def format_srt_time(seconds):\n",
        "        h, m, s, ms = int(seconds//3600), int((seconds%3600)//60), int(seconds%60), int((seconds%1)*1000)\n",
        "        return f\"{h:02}:{m:02}:{s:02},{ms:03}\"\n",
        "\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for idx, sub_data in enumerate(final_subtitles, start=1):\n",
        "            text = sub_data[\"text\"].replace(\" ,\", \",\").replace(\" .\", \".\")\n",
        "            formatted_lines = split_line_by_char_limit(text, max_chars_per_line)\n",
        "            f.write(f\"{idx}\\n\")\n",
        "            f.write(f\"{format_srt_time(sub_data['start'])} --> {format_srt_time(sub_data['end'])}\\n\")\n",
        "            f.write(\"\\n\".join(formatted_lines) + \"\\n\\n\")\n",
        "\n",
        "    # print(f\"SRT file '{output_file}' created with orphan-merging logic.\")\n",
        "\n",
        "\n",
        "def srt_making(upload_file):\n",
        "    root_path=\"./subtitle\"\n",
        "    os.makedirs(root_path, exist_ok=True)\n",
        "    model = load_model(device=\"cuda\")\n",
        "    if upload_file.endswith(\".mp4\"):\n",
        "      mono_audio_path = convert_video_to_mono_mp3(upload_file)\n",
        "    else:\n",
        "      mono_audio_path = ensure_mono(upload_file)\n",
        "    base=os.path.splitext(os.path.basename(upload_file))[0]\n",
        "    save_json_path=f\"{root_path}/{base}_word.json\"\n",
        "    word_srt_path =f\"{root_path}/{base}_word.srt\"\n",
        "    sentence_srt_path=f\"{root_path}/{base}_sentence.srt\"\n",
        "    text_path=f\"{root_path}/{base}_text.txt\"\n",
        "    transcription, word_level_timestamps = run_transcription(model, mono_audio_path,save_json_path)\n",
        "    unload_model(model)\n",
        "    write_word_srt(word_level_timestamps, output_file=word_srt_path, skip_punctuation=True)\n",
        "    write_sentence_srt(\n",
        "    word_level_timestamps,\n",
        "    output_file=sentence_srt_path,\n",
        "    max_lines=2,\n",
        "    max_duration_s=7.0,\n",
        "    max_chars_per_line=38,\n",
        "    hard_pause_threshold=0.5,\n",
        "    merge_pause_threshold=0.4\n",
        "    )\n",
        "    with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(transcription)\n",
        "    return sentence_srt_path,word_srt_path,save_json_path,text_path,transcription\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################\n",
        "audio_or_video_path = '/content/sample_fr_hibiki_crepes.mp3'  # @param {type: \"string\"}\n",
        "\n",
        "sentence_srt_path,word_srt_path,save_json_path,text_path,transcription=srt_making(audio_or_video_path)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(f\"Sentence SRT path: {sentence_srt_path}\")\n",
        "print(f\"Word SRT path: {word_srt_path}\")\n",
        "print(f\"JSON path: {save_json_path}\")\n",
        "print(f\"Text path: {text_path}\")\n",
        "print(f\"Transcription: {transcription}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "I_SAWzkAH2j4",
        "outputId": "65b7b3b6-e16d-45c1-acd7-1beac2e53d5a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence SRT path: ./subtitle/sample_fr_hibiki_crepes_sentence.srt\n",
            "Word SRT path: ./subtitle/sample_fr_hibiki_crepes_word.srt\n",
            "JSON path: ./subtitle/sample_fr_hibiki_crepes_word.json\n",
            "Text path: ./subtitle/sample_fr_hibiki_crepes_text.txt\n",
            "Transcription: Bonjour, aujourd'hui, nous alons preparez des crêpes, pour sous lait beaufort à de la farine, dessous, dulée, une passé de sel, de suc, et du beau. Pourquoi monsieur, mes tées la farine donnez ça la dieu, avec le sel, le suc. faits est un puit au milieu et verse iz le zoo. Comment ça mes nos jeux mots, comment les nos deux intépés, ajour tous le foire, et a petit. contour le est mes langé, la pate de tress et frites, ci et vous paretre pesses, arragité un peux de l'e, arragité un suite le beaufond du roche radi, mes la gébienne, fait qu'er et créme danse ne poire chose, vers est un petit trouge de pate de la poire, fait à mouvement de rota sion pour é partire la pate surtout la soufise, pose et sur le foe, et comme le toux de la crepe sur coeur angreux, claire, et étendre à rotunde, les équitres envolutions une discote, et à crepe et prete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Subtitle\n",
        "from google.colab import files\n",
        "files.download(sentence_srt_path)\n",
        "files.download(word_srt_path)\n",
        "files.download(save_json_path)\n",
        "files.download(text_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "cellView": "form",
        "id": "bptOVcMhMhM9",
        "outputId": "421106eb-cfc8-49ec-9e27-a1b0048be1a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_31f38797-a404-49f2-b185-55083e059574\", \"sample_fr_hibiki_crepes_sentence.srt\", 1374)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4389ad11-d3f8-4a09-9c79-5e6e4705e404\", \"sample_fr_hibiki_crepes_word.srt\", 6505)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5c905454-15c6-4493-8ddc-4dd0c0c0fa61\", \"sample_fr_hibiki_crepes_word.json\", 14525)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d7240774-1523-4c6d-a1e8-863e397e8f23\", \"sample_fr_hibiki_crepes_text.txt\", 872)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}